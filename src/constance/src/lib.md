The Constance RTOS

[![Constance and Fluttershy](https://derpicdn.net/img/2018/5/25/1740985/medium.png)](http://derpibooru.org/1740985)

<div class="toc-header"></div>

- [Note to Application Developers](#note-to-application-developers)
- [Configuring the Kernel](#configuring-the-kernel)
    - [Trait-based Composition](#trait-based-composition)
    - [Static Configuration](#static-configuration)
- [System States](#system-states)
- [Threads](#threads)
- [Contexts](#contexts)
- [Interrupt Handling Framework](#interrupt-handling-framework)
- [Modules](#modules)  <!-- this section is generated by rustdoc -->
- [Macros](#macros)  <!-- this section is generated by rustdoc -->

# Note to Application Developers

The implementation code heavily relies on constant propagation, dead code elimination, and “zero-cost” abstractions. Without optimization, it might exhibit a massive code bloat and excessive stack consumption. To change the optimization level for debug builds, add the following lines to your Cargo workspace's `Cargo.toml`:

```toml
[profile.dev]
opt-level = 2
```

# Configuring the Kernel

## Trait-based Composition

The Constance RTOS utilizes Rust's trait system to allow system designers to construct a system in a modular way.

The following pseudocode outlines the traits and types involved in hooking up the kernel, port, and application to each other.

```rust,ignore
crate constance {
    /// Associates `System` with kernel-private data. Implemented by `build!`.
    /// The kernel-private data includes port-specific types.
    unsafe trait KernelCfg1 {
        /* ... */
    }

    /// Implemented by a port.
    unsafe trait Port: KernelCfg1 {
        type TaskState;
        fn dispatch();
        /* ... */
    }

    /// Associates `System` with kernel-private data. Implemented by `build!`.
    /// The kernel-private data includes port-specific types.
    unsafe trait KernelCfg2: Port {
        const TASK_CFG: &'static [TaskCfg<Self::TaskState>];
        /* ... */
    }

    /// The API used by the application and the port. This is automatically
    /// implemented when a type has sufficient trait `impl`s.
    trait Kernel: Port + KernelCfg2 {}

    impl<T: Port + KernelCfg1 + KernelCfg2> Kernel for T { /* ... */ }

    /// Instantiate the `static`s necessary for the kernel's operation. This is
    /// absolutely impossible to do with blanket `impl`s.
    macro_rules! build {
        ($sys:ty, $configure:expr) => {
            unsafe impl $crate::KernelCfg1 for $sys {}
            unsafe impl $crate::KernelCfg2 for $sys {
                const TASK_CFG: &'static [TaskCfg<Self::TaskState>] = /* ... */;
                /* ... */
            }
        };
    }
}

crate constance_xxx_port {
    // The following approach doesn't work because of a circular dependency in
    // blanket `impl`s:
    //
    // impl<T: constance::Kernel> constance::Port for T {}

    // Instead, `Port` should be implemented specifically for a type. This is
    // facilitated by a macro, which also has an advantage of giving the port an
    // opportunity to insert port-specific code (such as `static`s and inline
    // assembler) referencing `$sys` to the application.
    macro_rules! use_port {
        (unsafe struct $sys:ident) => {
            struct $sys;

            // Assume `$sys: Kernel`
            unsafe impl constance::Port for $sys {
                /* ... */
            }
        };
    }
}

crate your_app {
    constance_xxx_port::use_port!(unsafe struct System);

    struct Objects {
        task1: constance::Task<System>,
    }

    static COTTAGE: Objects = constance::build!(System, configure_app);

    // The configuration function. See "Static Configuration" for details.
    fn configure_app(b: &mut constance::CfgBuilder<System>) -> Objects {
        Objects { task1: /* ... */ }
    }
}
```

## Static Configuration

Kernel objects are created in **a configuration function** having the signature `const fn (&mut `[`CfgBuilder`]`) -> T` (+ optional `self` and trailing extra parameters). The code generated by [`build!`] calls **a top-level configuration function** (at compile time) to collect information such as a set of kernel objects that need to be instantiated. This information is used to implement [`KernelCfg1`] and [`KernelCfg2`] on a given system type. At the same time, this process also produces handles to the defined kernel objects (such as [`Task`]), which can be returned from a configuration function directly or packaged in a user-defined container type. `build!` returns the evaluation result of the top-level configuration function. By storing this in a `const` variable, application code can access the defined kernel objects.

[`CfgBuilder`]: crate::kernel::cfg::CfgBuilder
[`KernelCfg1`]: crate::kernel::KernelCfg1
[`KernelCfg2`]: crate::kernel::KernelCfg2
[`Task`]: crate::kernel::Task

Configuration functions can call other configuration functions. This is useful to attribute a certain semantics to a group of kernel objects, making them behave in a meaningful way as a whole, and expose a whole new, higher-level interface. For example, a mutex object similar to `std::sync::Mutex` can be created by combining a low-level mutex object (not implemented yet) and a [`Hunk`]`<System, UnsafeCell<T>>`.

[`Hunk`]: crate::kernel::Hunk

The constructors of kernel objects are configuration functions by themselves, but they are different from normal configuration functions in that they can actually mutate the contents of `CfgBuilder` (which `build!` will use to create kernel structures in the final form), ultimately shaping the outcome of the configuration process. Therefore, they are the smallest building blocks of configuration functions.

It's possible to write a configuration function directly. However, [`configure!`] can make this process easier by providing macros that offer more concise syntaxes for common patterns.

# System States

A system can be in some of the system states described in this section at any point.

**CPU Lock** disables all managed interrupts and dispatching. On a uniprocessor system (which this kernel targets), this is a convenient way to create a critical section to protect a shared resource from concurrent accesses. Most system services are unavailable when CPU Lock is active, and will return [`BadContext`]. Application code can use [`acquire_cpu_lock`] to activate CPU Lock.

[`acquire_cpu_lock`]: crate::kernel::Kernel::acquire_cpu_lock
[`BadContext`]: crate::kernel::ResultCode::BadContext

Like a lock guard of a mutex, CPU Lock can be thought of as something to be “owned” by a current thread. This conception allows it to be seamlessly integrated with Rust's vocabulary and mental model around the ownership model.

**Priority Boost** temporarily raises the effective priority of the current task to higher than any values possible in normal circumstances. Priority Boost can only be activated or deactivated in a task context. Potentially blocking system services are disallowed when Priority Boost is active, and will return [`BadContext`]. Application code can use [`boost_priority`] to activate Priority Boost.

[`boost_priority`]: crate::kernel::Kernel::boost_priority
[`BadContext`]: crate::kernel::ResultCode::BadContext

<div class="admonition-follows"></div>

> **Relation to Other Specifications:** Inspired from [the μITRON4.0 specification](http://www.ertl.jp/ITRON/SPEC/mitron4-e.html). CPU Lock and Priority Boost correspond to a CPU locked state and a dispatching state from μITRON4.0, respectively. In contrast to this specification, both concepts are denoted by proper nouns in the Constance RTOS. This means phrases like “when the CPU is locked” are not allowed.
>
> CPU Lock corresponds to `SuspendOSInterrupts` and `ResumeOSInterrupts` from the OSEK/VDX specification.

# Threads

**An (execution) thread** is a sequence of instructions executed by a processor. There can be multiple threads existing at the same time and the kernel is responsible for scheduling the execution of threads. The location in a program where a thread starts execution is called **an entry point function** for the thread. A thread exits when it returns from its entry point function¹ or calls [`exit_task`](crate::kernel::Kernel::exit_task) (valid only for tasks).

 ¹ More precisely, a thread starts execution with a hypothetical function call to the entry point function, and it exits when it returns from this hypothetical function call.

There are two types of kernel objects that define the properties of threads such as how and when they are created and whether they can block or not. (To be precise, they are not threads by themselves but often treated as such for brevity. Matching them to threads doesn't cause much confusion in practice because each of them can only map to up to one thread at any moment.)

 - **Interrupt handlers** start execution in response to asynchronous external events (interrupts). They always run to completion but can be preempted by other interrupt handlers. No blocking system calls are allowed in an interrupt handler.

 - **[Tasks]** are kernel objects whose execution is controlled by application code. Each task encapsulates a variety of state data necessary for the execution and scheduling of the associated thread, such as [a stack region] to store local variables and activation frames, the current [priority], the [parking] state of the task, and a memory region used to save the state of CPU registers when the task is blocked or preempted. The associated thread can be started by **[activating]** that task. A task-based thread can make blocking system calls, which will temporarily block the execution of the thread until certain conditions are met. Task-based threads can be preempted by any kinds of threads.

[Tasks]: crate::kernel::Task
[a stack region]: crate::kernel::cfg::CfgTaskBuilder::stack_size
[priority]: crate::kernel::cfg::CfgTaskBuilder::priority
[parking]: crate::kernel::Task::unpark
[activating]: crate::kernel::Task::activate

<div class="admonition-follows"></div>

> **Relation to Other Specifications:** Not many kernel designs use the word “thread” to describe the concept that applies to both of interrupts and tasks (one notable exception being [TI-RTOS]), most likely because threads are used to refer to a specific concept in general-purpose operating systems, or they are simply considered synonymous with tasks. Despite that, it was decided that “thread” was an appropriate term to refer to this concept. The primary factors that drove this decision include: (1) the need for a conceptual entity that can “own” locks, and (2) that this concept is important for discussing thread safety without substituting every mention of “thread” with “task or interrupt handler”.
>
> The closest concept in [the μITRON4.0 specification](http://www.ertl.jp/ITRON/SPEC/mitron4-e.html) is *processing units*.

[TI-RTOS]: http://software-dl.ti.com/lprf/simplelink_cc13x0_sdk/1_30_00_06/exports/docs/ti154stack/ti154stack-sdg/ti154stack-sdg/tirtos/rtos-overview.html

# Contexts

A context is a general term which is often used to describe the “environment” a function executes in. Terms like *a task context* are used to specify the type of thread a calling thread is expected to be. The following list shows the terms we use to describe contexts throughout this kernel's documentation:

 - **A task context** means the current [thread] pertains to a task.
 - **An interrupt context** means the current thread pertains to an interrupt handler.
 - **A waitable context** means a task context and that [Priority Boost] is inactive.

[thread]: #threads
[Priority Boost]: #system-states

<div class="admonition-follows"></div>

> **Relation to Other Specifications:** [The μITRON4.0 specification], [the AUTOSAR OS specification], and [RTEMS]'s user manuals use the term “context” in a similar way.

[The μITRON4.0 specification]: http://www.ertl.jp/ITRON/SPEC/mitron4-e.html
[The AUTOSAR OS specification]: https://www.autosar.org/fileadmin/user_upload/standards/classic/4-3/AUTOSAR_SWS_OS.pdf
[RTEMS]: https://www.rtems.org

# Interrupt Handling Framework

A port may support managing interrupt lines and interrupt handlers through an interface defined by the kernel. When it's supported, an application can use this facility to configure interrupt lines and attach interrupt handlers. It's **port-defined** whether a port supports managing or *not* managing interrupt lines and interrupt handlers.

The benefits of providing a standardized interface for interrupts include: (1) increased portability of applications and libraries across target platforms, (2) well-defined semantics of system calls inside an interrupt handler, and (3) decoupling hardware driver components on a system with a non-vectorized interrupt controller or multiplexed interrupt lines. The downsides include: (1) obscuring non-standard hardware features, (2) interference with other ways of managing interrupts (e.g., board support packages, IDEs), (3) additional layer of abstraction that makes the system mechanism unclear.

<div class="admonition-follows"></div>

> **Port Implementation Note:** System calls can provide well-defined semantics inside an interrupt handler only if the port adheres to this interrupt handling framework. If a port developer chooses not to follow this, they are responsible to properly explain the interaction between interrupts and the kernel.

An interrupt request is delivered to a processor by sending a hardware signal to an interrupt controller through **an interrupt line**. It's possible that more than one interrupt sources are connected to a single interrupt line. Upon receiving an interrupt request, the interrupt controller translates the interrupt line to **an interrupt number** and transfers the control to **the first-level interrupt handler** associated with that interrupt number.

Each interrupt line has configurable attributes such as **an interrupt priority**. An application can instruct the kernel to configure them at boot time by [`CfgInterruptLineBuilder`] or at runtime by [`InterruptLine`]. The interpretation of interrupt priority values is up to a port, but they are usually used to define precedence among interrupt lines in some way, such as favoring one over another when multiple interrupt requests are received at the same time, or allowing a higher-priority interrupt handler to preempt another.

[`CfgInterruptLineBuilder`]: crate::kernel::cfg::CfgInterruptLineBuilder
[`InterruptLine`]: crate::kernel::InterruptLine

The kernel occasionally disables interrupts by activating CPU Lock. The additional interrupt latency introduced by this can pose a problem for time-sensitive applications. To resolve this problem, a port may implement CPU Lock in a way that doesn't disable interrupt lines with a certain priority value and higher. Such priority values and the first-/second-level interrupt handlers for such interrupt lines are said to be **unmanaged**. The behavior of system calls inside unmanaged interrupt handlers is undefined. Interrupt handlers that aren't unmanaged are said to be **managed**.

An application can register one or more **(second-level) interrupt handlers** to an interrupt number. They execute in a serial fashion inside a first-level interrupt handler for the interrupt number. The static configuration system automatically combine multiple second-level interrupt handlers into one (thus taking care of the “execute in a serial fashion” part). **It's up to a port to generate a first-level interrupt handler** that executes in an appropriate situation, takes care of low-level tasks such as saving and restoring registers, and calls the (combined) second-level interrupt handler.

Interrupt handlers execute with CPU Lock inactive and may return with CPU Lock either active or inactive. Some system calls are not allowed in there and will return [`BadContext`].

The behavior of system calls is undefined inside an unmanaged interrupt handler. The property of being protected from programming errors caused by making system calls inside an unmanaged interrupt handler is called **unmanaged safety**. Most system services are not marked as `unsafe`, so in order to ensure unmanaged safety, safe code shouldn't be allowed to register an interrupt handler that potentially executes as an unmanaged interrupt handler. On the other hand, the number of `unsafe` blocks in application code should be minimized in common use cases. To meet this goal, this framework employs several safeguards: (1) Interrupt handlers can be [explicitly marked] as **unmanaged-safe** (safe to use as an unmanaged interrupt handler), but this requires an `unsafe` block. (2) An interrupt line must be initialized with a priority value that falls within [a managed range] if it has an non-unmanaged-safe interrupt service handler. (3) When [changing] the priority of an interrupt line, the new priority must be in a managed range. It's possible to [bypass] this check, but this requires an `unsafe` block.

[explicitly marked]: crate::kernel::cfg::CfgInterruptHandlerBuilder::unmanaged
[changing]: crate::kernel::InterruptLine::set_priority
[bypass]: crate::kernel::InterruptLine::set_priority_unchecked
[a managed range]: crate::kernel::Port::MANAGED_INTERRUPT_PRIORITY_RANGE

<div class="admonition-follows"></div>

> **Relation to Other Specifications:** The interrupt handling framework was largely inspired from [the μITRON4.0 specification](http://www.ertl.jp/ITRON/SPEC/mitron4-e.html). The method of leveraging Rust's `unsafe` system to ensure unmanaged safety is obviously Rust-specific and novel.
>
> Interrupt handlers and interrupt service routines (terms from μITRON4.0) have been renamed to first-level interrupt handlers and (second-level) interrupt handlers, respectively, because “interrupt service routine” was way too long to type and abbreviating it would result in a set of type names which is either excessively inconsistent (`InterruptLine`, `Irq`) or bizarre (`InterruptLine`, `InterruptRq`). Removing the term “interrupt service routine” should also remove a source of confusion because interrupt handlers and interrupt service routines are often regarded as synonymous to each other (as evident in [the Wikipedia article] on interrupt handler), whereas there is a clear sequential relationship between first-level and second-level.
>
> The OSEK/VDX specification divides interrupt service routines into category 1 and 2 similarly to our managed and unmanaged interrupt handlers.

[`BadContext`]: crate::kernel::ResultCode::BadContext
[the Wikipedia article]: https://en.wikipedia.org/w/index.php?title=Interrupt_handler&oldid=934917582
